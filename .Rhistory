p + scale_fill_brewer(palette="Reds")
ggplot(scale[order(scale$type),])+geom_bar(aes(x=t,y=bmi,fill=type),stat="identity",position="stack")
ggplot(scale[order(scale$type, decreasing = T),])+geom_bar(aes(x=t,y=bmi,fill=type),stat="identity",position="stack")
scale <- data.frame(type=c("underweight","normal","overweight","obese"),bmi=c(18.5, 6.5, 5, 20),t=c(1,1,1,1))
ggplot(scale[order(scale$type, decreasing = T),])+geom_bar(aes(x=t,y=bmi,fill=type),stat="identity",position="stack")
ggplot(scale)+geom_bar(aes(x=t,y=bmi,fill=type),stat="identity",position="stack")
ggplot(scale[order(scale$type, decreasing = F),])+geom_bar(aes(x=t,y=bmi,fill=type),stat="identity",position="stack")
ggplot(scale[order(scale$type, decreasing = F),],aes(x=t,y=bmi,fill=type))+geom_bar(stat="identity",position="stack")
ggplot(scale[order(scale$type, decreasing = T),],aes(x=t,y=bmi,fill=type))+geom_bar(stat="identity",position="stack")
ggplot(scale[sample(1:4),],aes(x=t,y=bmi,fill=type))+geom_bar(stat="identity",position="stack")
ggplot(scale[sample(1:4),],aes(x=t,y=bmi,fill=type))+geom_bar(stat="identity")
ggplot(scale[sample(1:4),],aes(x=t,y=bmi,fill=type))+geom_bar(stat="identity")
ggplot(scale[order(scale$type, decreasing = T),],aes(x=t,y=bmi,fill=type))+geom_bar(stat="identity")
ggplot(scale,aes(x=t,y=bmi,fill=type))+geom_bar(stat="identity")
View(df)
View(scale)
View(scale)
scale <- data.frame(tp=c("underweight","normal","overweight","obese"),bmi=c(18.5, 6.5, 5, 20),t=c(1,1,1,1))
ggplot(scale)+geom_bar(aes(x=t,y=bmi,fill=tp),stat="identity",position="stack")
str(scale)
scale$tp <- as.character(scale$tp)
ggplot(scale)+geom_bar(aes(x=t,y=bmi,fill=tp),stat="identity",position="stack")
str(scale)
scale <- data.frame(tp=c("underweight","normal","overweight","obese"),bmi=c(18.5, 6.5, 5, 20),t=c(1,1,1,1))
str(scale$tp)
summary(scale$tp)
head(scale$tp)
shiny::runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
install.packages(c("BH", "boot", "caret", "crayon", "curl", "DBI", "dplyr", "evaluate", "foreign", "gridExtra", "httr", "knitr", "Matrix", "mgcv", "openssl", "PKI", "quantmod", "R6", "Rcpp", "RcppArmadillo", "relations", "reshape", "rlang", "rsconnect", "RSQLite", "rstudioapi", "scales", "spam", "sqldf", "tibble", "tidyr", "TTR", "XML", "xts"))
shiny::runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
sc <- data.frame(type= factor(c("underweight","normal","overweight","obese"),levels=1:4),
bmi=c(18.5, 6.5, 5, 20),t=c(1,1,1,1))
View(sc)
View(sc)
sc <- data.frame(type= c("underweight","normal","overweight","obese"),
bmi=c(18.5, 6.5, 5, 20),t=c(1,1,1,1))
View(sc)
str(sc)
sc$type <- factor(sc$type, levels = 1:4)
str(sc)
sc <- data.frame(type=c("underweight","normal","overweight","obese"),
bmi=c(18.5, 6.5, 5, 20),t=c(1,1,1,1))
sc$type <- factor(sc$type, ordered = FALSE)
str(sc)
sc$type <- factor(sc$type, ordered = TRUE)
str(sc)
sc$type <- factor(sc$type, ordered = FALSE)
View(sc)
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
View(sc)
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
b <- ggplot(data=mpg, aes(x=fl))
str(mpg$fl)
summary(mpg$fl)
n <- b + geom_bar(aes(fill=fl))
n + scale_fill_manual(values=c("skyblue","royalblue","blue","navy"), limits=c("d","e","p","r"),breaks=c("d","e","p","r"), labels=c("D","E","P","R"))
n <- b + geom_col(aes(fill=fl))
n + scale_fill_manual(values=c("skyblue","royalblue","blue","navy"), limits=c("d","e","p","r"),breaks=c("d","e","p","r"), labels=c("D","E","P","R"))
b + geom_bar(aes(fill=fl))
n <- b + geom_bar(aes(fill=fl))
n + scale_fill_manual(values=c("skyblue","royalblue","blue","navy"), limits=c("d","e","p","r"),breaks=c("d","e","p","r"), labels=c("D","E","P","R"))
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
install.packages('rsconnect')
install.packages("rsconnect")
rsconnect::setAccountInfo(name='stellali', token='BF349CFE5C95605A34D94EBA7CC4FDC9', secret='D2gzXfvKohU3WAtjlb8+6WaRXYPaB3/7ieIrX1IT')
shiny::runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
runApp('Google Drive/Coursera-DataScience/9_Creating_Data_Products/HealthyDiet')
setwd("~/Google Drive/Coursera-DataScience/Capstone Project/final/en_US/")
con.twt <- file("en_US.twitter.txt", "r"); twt <- readLines(con.twt); close(con.twt)
con.news <- file("en_US.news.txt","r"); news <- readLines(con.news); close(con.news)
con.blogs <- file("en_US.blogs.txt", "r"); blogs <- readLines(con.blogs); close(con.blogs)
rm(con.twt); rm(con.news); rm(con.blogs)
library(NLP)
library(ggplot2)
GetVoc <- function(source, smpsize=0.5) {
l <- length(source)
smp <- sample(1:l, l * smpsize)
s.smp <- source[smp] #get a random smaller sample
s.smp <- tolower(s.smp)
s.clean <- gsub("[^a-z']+", " ", s.smp) #remove all non-alphabetic characters, except for "'"
s.clean <- gsub("'{2,}", "'", s.clean)
s.clean <- gsub(" '+|'+ |^'+|'+$", " ", s.clean) #remove "'" that are not between two letters
text <- paste(s.clean, collapse = " ") #make whole text in one string
voc <- strsplit(text, split = " ")[[1]] #
voc <- voc[voc != ""]
return(voc)
}
GetVoc <- function(source, smpsize=0.5) {
l <- length(source)
smp <- sample(1:l, l * smpsize)
s.smp <- source[smp] #get a random smaller sample
s.smp <- tolower(s.smp)
s.clean <- gsub("[^a-z']+", " ", s.smp) #remove all non-alphabetic characters, except for "'"
s.clean <- gsub("'{2,}", "'", s.clean)
s.clean <- gsub(" '|' ", " ", s.clean) #remove "'" that are not between two letters
s.clean <- gsub("^'|'$", "", s.clean) #remove "'" that are at the beginning or end of a sentence
text <- paste(s.clean, collapse = " ") #make whole text in one string
voc <- strsplit(text, split = " ")[[1]] #
voc <- voc[voc != ""]
return(voc)
}
GetDict <- function(vocabulary) {
dict <- as.data.frame(xtabs(~vocabulary))
colnames(dict) <- c("Vocabulary", "Freq")
dict <- dict[order(dict$Freq, decreasing = T), ]
dict <- cbind(dict, pct = dict$Freq/length(vocabulary))
return(dict)
}
voc.twt.all <- GetVoc(twt, smpsize=1) #extract vocabulary from twitter file
dict.twt.all <- GetDict(voc.twt.all) #build a dictionary with all the data
l.t <- length(voc.twt.all)
ld.t <- length(dict.twt.all$Vocabulary)
head(dict.twt.all$Vocabulary[order(dict.twt.all$Vocabulary)])
GetVoc <- function(source, smpsize=0.5) {
l <- length(source)
smp <- sample(1:l, l * smpsize)
s.smp <- source[smp] #get a random smaller sample
s.smp <- tolower(s.smp)
s.clean <- gsub("[^a-z']+", " ", s.smp) #remove all non-alphabetic characters, except for "'"
s.clean <- gsub("'{2,}", "'", s.clean)
s.clean <- gsub(" +'|' +", " ", s.clean) #remove "'" that are not between two letters
s.clean <- gsub("^'|'$", "", s.clean) #remove "'" that are at the beginning or end of a sentence
text <- paste(s.clean, collapse = " ") #make whole text in one string
voc <- strsplit(text, split = " ")[[1]] #
voc <- voc[voc != ""]
return(voc)
}
voc.twt.all <- GetVoc(twt, smpsize=1) #extract vocabulary from twitter file
dict.twt.all <- GetDict(voc.twt.all) #build a dictionary with all the data
l.t <- length(voc.twt.all)
ld.t <- length(dict.twt.all$Vocabulary)
head(dict.twt.all$Vocabulary[order(dict.twt.all$Vocabulary)])
" '" %in% "' '"
sub(" '", "!", x=c("' '"))
sub(" '|' ", "!", x=c("' '"))
sub(" '|' ", "!", x=c("'  '"))
sub(" '|' ", "!", x=c(" '  '"))
gsub(" '|' ", "!", x=c("'  '"))
gsub(" '|' ", "!", x=c(" '  '"))
gsub(" '|' ", "!", x=c(" '' "))
gsub(" '|' ", " ", x=c(" '' "))
gsub(" '|' ", " ", x=c("I found the great arrangement of Queens' 'Angie' which people sang if I introduce my name"))
gsub(" '|' |' '", " ", x=c("I found the great arrangement of Queens' 'Angie' which people sang if I introduce my name"))
GetVoc <- function(source, smpsize=0.5) {
l <- length(source)
smp <- sample(1:l, l * smpsize)
s.smp <- source[smp] #get a random smaller sample
s.smp <- tolower(s.smp)
s.clean <- gsub("[^a-z']+", " ", s.smp) #remove all non-alphabetic characters, except for "'"
s.clean <- gsub("'{2,}", "'", s.clean)
s.clean <- gsub("' | '|' '", " ", s.clean) #remove "'" that are not between two letters
s.clean <- gsub("^'|'$", "", s.clean) #remove "'" that are at the beginning or end of a sentence
text <- paste(s.clean, collapse = " ") #make whole text in one string
voc <- strsplit(text, split = " ")[[1]] #
voc <- voc[voc != ""]
return(voc)
}
voc.twt.all <- GetVoc(twt, smpsize=1) #extract vocabulary from twitter file
dict.twt.all <- GetDict(voc.twt.all)
head(dict.twt.all$Vocabulary[order(dict.twt.all$Vocabulary)])
voc.news.all <- GetVoc(news, smpsize=1)
voc.blogs.all <- GetVoc(blogs, smpsize=1)
dict.news.all <- as.data.frame(xtabs(~voc.news.all))
dict.blogs.all <- as.data.frame(xtabs(~voc.blogs.all))
head(dict.news.all)
head(dict.blogs.all)
rm(voc.news.all); rm(voc.blogs.all)
rm(dict.news.all); rm(dict.blogs.all)
set.seed(1017)
voc.twt1 <- GetVoc(twt, smpsize=0.01)
dict.twt1 <- GetDict(voc.twt1)
as.character(head(dict.twt.all$Vocabulary, 10))
as.character(head(dict.twt1$Vocabulary, 10))
l.t1 <- length(voc.twt1); ld.t1 <- length(dict.twt1$Vocabulary)
dict.twt1$cpct[1] <- dict.twt1$pct[1]
for(i in 2:ld.t1) {
dict.twt1$cpct[i] <- dict.twt1$pct[i] + dict.twt1$cpct[i-1]
}
rownames(dict.twt1) <- 1:length(dict.twt1$Vocabulary)
head(dict.twt1)
dict.twt1[dict.twt1$cpct>0.5 & dict.twt1$cpct < 0.501, ][1, ]
dict.twt1[dict.twt1$cpct>0.8 & dict.twt1$cpct < 0.801, ][1, ]
dict.twt1[dict.twt1$cpct>0.9 & dict.twt1$cpct < 0.901, ][1, ]
dict.twt1[dict.twt1$cpct>0.7 & dict.twt1$cpct < 0.701, ][1, ]
rownames(dict.twt.all) <- 1:length(dict.twt.all$Vocabulary)
sum(dict.twt.all$pct[1:590])
sum(dict.twt.all$pct[1:4703])
length(dict.twt.all$Vocabulary[dict.twt.all$Freq==1])
length(dict.twt1$Vocabulary[dict.twt1$Freq==1])
dict.twt.all$cpct[1] <- dict.twt.all$pct[1]
for(i in 2:ld.t) {
dict.twt.all$cpct[i] <- dict.twt.all$pct[i] + dict.twt.all$cpct[i-1]
}
l.t <- length(voc.twt.all)
ld.t <- length(dict.twt.all$Vocabulary)
cumsum(1:10)
cumprod(1:10)
cummin(c(3:1, 2:0, 4:2))
x <- cumsum(dict.twt1$pct)
x == dict.twt1$cpct
head(dict.twt1$cpct, 20)
head(x, 20)
dict.twt.all$cpct <- cumsum(dict.twt.all$pct)
head(dict.twt.all)
dict.twt.all[dict.twt.all$cpct>0.5 & dict.twt.all$cpct < 0.501, ][1, ]
dict.twt.all[dict.twt.all$cpct>0.7 & dict.twt.all$cpct < 0.701, ][1, ]
dict.twt.all[dict.twt.all$cpct>0.9 & dict.twt.all$cpct < 0.901, ][1, ]
dict.twt1[dict.twt1$cpct>0.5 & dict.twt1$cpct < 0.501, ][1, ]
dict.twt1[dict.twt1$cpct>0.7 & dict.twt1$cpct < 0.701, ][1, ]
dict.twt1[dict.twt1$cpct>0.9 & dict.twt1$cpct < 0.901, ][1, ]
dict.twt.all[dict.twt.all$cpct>0.5 & dict.twt.all$cpct < 0.501, ][1, ]
ggplot(dict.twt1, aes(y=cpct)) + geom_point(size=0.2) + xlab("Index") + ylab("Cummulative Percentage")
ggplot(dict.twt1, aes(x=rownames(dict.twt1),y=cpct)) + geom_point(size=0.2) + xlab("Index") + ylab("Cummulative Percentage")
head(rownames(dict.twt1))
ggplot(dict.twt1, aes(x=as.numeric(rownames(dict.twt1)),y=cpct)) + geom_point(size=0.2) + xlab("Index") + ylab("Cummulative Percentage")
top.t <- dict.twt.all$Vocabulary[1:590]
top.t1 <- dict.twt1$Vocabulary[1:590]
sum(top.t %in% top.t1)
a1 = 0; a2 = 0
for (i in 1:590) {
b1 = top.t1[i] %in% top.t
b2 = top.t[i] %in% top.t1
a1 = a1 + b1
a2 = a2 + b2
}
sum(dict.twt.all$pct[dict.twt.all$Vocabulary %in% top.t1])
ggplot(voc.twt1, aes(Freq)) + geom_histogram(binwidth = 0.3)
ggplot(voc.twt1, aes(as.numeric(Freq))) + geom_histogram(binwidth = 0.3)
summary(dict.twt1)
str(dict.twt1)
ggplot(dict.twt1, aes(Freq)) + geom_histogram(binwidth = 0.3)
ggplot(dict.twt1, aes(Freq)) + geom_histogram(binwidth = 3)
ggplot(dict.twt1, aes(Freq)) + geom_histogram(binwidth = 5)
dev.off()
rm(l.t1);rm(ld.t1)
rm(top10.t); rm(top10.t1); rm(top.t); rm(top.t1)
rm(dict.twt.all)
rm(a1)
rm(a2)
rm(b1,b2,i)
rm(x)
rm(l.t, ld.t)
set.seed(1017)
voc.news <- GetVoc(news, smpsize=0.01)
voc.blogs <- GetVoc(blogs, smpsize=0.01)
unigram <- c(voc.twt1, voc.news, voc.blogs)
dict.unigram <- GetDict(unigram)
length(dict.unigram[dict.unigram$Freq==1, 1])/length(dict.unigram$Vocabulary)
library(NLP)
bigrams <- vapply(ngrams(unigram, 2), paste, "", collapse = " ")
dict.bigrams <- GetDict(bigrams)
trigrams <- vapply(ngrams(unigram, 3), paste, "", collapse = " ")
dict.trigrams <- GetDict(trigrams)
GetDict <- function(vocabulary) {
dict <- as.data.frame(xtabs(~vocabulary))
colnames(dict) <- c("Vocabulary", "Freq")
dict <- dict[order(dict$Freq, decreasing = T), ]
dict <- cbind(dict, pct = dict$Freq/length(vocabulary))
rownames(dict) <- 1:length(dict$Vocabulary)
return(dict)
}
dict.bigrams <- GetDict(bigrams)
head(dict.bigrams)
head(dict.trigrams)
dict.trigrams <- GetDict(trigrams)
head(dict.trigrams)
dict.unigram$cpct <- cumsum(dict.unigram$pct)
dict.bigram$cpct <- cumsum(dict.bigram$pct)
dict.bigrams$cpct <- cumsum(dict.bigrams$pct)
dict.trigrams$cpct <- cumsum(dict.trigrams$pct)
dict.unigram[dict.unigram$cpct>0.5 & dict.unigram$cpct < 0.501, ]
dict.unigram[dict.unigram$cpct>0.9 & dict.unigram$cpct < 0.901, ]
head(dict.unigram)
head(dict.bigram)
head(dict.bigrams)
dict.unigram <- GetDict(unigram)
head(dict.unigram)
dict.unigram$cpct <- cumsum(dict.unigram$pct)
dict.unigram[dict.unigram$cpct>0.5 & dict.unigram$cpct < 0.501, ][1]
dict.unigram[dict.unigram$cpct>0.5 & dict.unigram$cpct < 0.501, ][1, ]
rownames(dict.unigram[dict.unigram$cpct>0.5 & dict.unigram$cpct < 0.501, ])
rownames(dict.unigram[dict.unigram$cpct>0.9 & dict.unigram$cpct < 0.901, ][1, ])
rownames(dict.bigrams[dict.bigrams$cpct>0.5 & dict.bigrams$cpct < 0.501, ][1, ])
rownames(dict.trigrams[dict.trigrams$cpct>0.5 & dict.trigrams$cpct < 0.501, ][1, ])
rownames(dict.trigrams[dict.trigrams$cpct>0.9 & dict.trigrams$cpct < 0.901, ][1, ])
rownames(dict.bigrams[dict.bigrams$cpct>0.9 & dict.bigrams$cpct < 0.901, ][1, ])
ggplot(dict.bigrams, aes(Freq)) + geom_histogram(binwidth = 5)
ggplot(dict.bigrams, aes(log10(Freq))) + geom_histogram(binwidth = 5)
ggplot(dict.bigrams, aes(Freq)) + geom_histogram(binwidth = 5)
ggplot(dict.bigrams, aes(Freq)) + geom_histogram(binwidth = 100)
ggplot(dict.bigrams, aes(log10(pct))) + geom_histogram(binwidth = 100)
ggplot(dict.bigrams, aes(log10(pct))) + geom_histogram(binwidth = 1)
ggplot(dict.bigrams, aes(log10(pct))) + geom_histogram(binwidth = 0.1)
ggplot(dict.bigrams, aes(-log10(pct))) + geom_histogram(binwidth = 0.1)
ggplot(dict.bigrams, aes(-log10(pct))) + geom_histogram(binwidth = 0.5)
ggplot(dict.bigrams, aes(-log10(pct))) + geom_histogram(binwidth = 0.3)
a <- rnorm(100, mean=0,sd=1)
hist(a)
ggplot(dict.bigrams, aes(-log10(pct))) + geom_histogram(binwidth = 0.3)
ggplot(dict.bigrams, aes(Freq) + geom_histogram(binwidth = 1000)
ggplot(dict.bigrams, aes(Freq)) + geom_histogram(binwidth = 1000)
ggplot(dict.bigrams, aes(log(Freq))) + geom_histogram(binwidth = 10)
ggplot(dict.bigrams, aes(log(Freq))) + geom_histogram(binwidth = 1)
ggplot(dict.bigrams, aes(log10(Freq))) + geom_histogram(binwidth = 1)
ggplot(dict.bigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.1)
ggplot(dict.bigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.2)
ggplot(dict.bigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.3)
ggplot(dict.bigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.25)
ggplot(dict.unigram, aes(log10(Freq))) + geom_histogram(binwidth = 0.25)
ggplot(dict.trigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.25)
ggplot(dict.trigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.25)
par(mfrow(c(1,3)))
library(graphics)
par(mfrow(c(1,3)))
par(mfrow=c(1,3))
ggplot(dict.unigram, aes(log10(Freq))) + geom_histogram(binwidth = 0.25) + ggtitle("Unigram")
ggplot(dict.bigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.25) + ggtitle("bigrams")
ggplot(dict.trigrams, aes(log10(Freq))) + geom_histogram(binwidth = 0.25)+ ggtitle("Trigrams")
install.packages("gridExtra")
library(gridExtra)
shiny::runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
load("~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/unigram.RData")
head(uni.dict)
load("~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/bigrams.RData")
load("~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/trigrams.RData")
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
install.packages("shinythemes")
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
library("markdown", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
knit_with_parameters('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/Tab1Intro.Rmd')
unlink('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/Tab1Intro_cache', recursive = TRUE)
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
View(GetBestGuess)
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
runApp('Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard')
setwd("~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard")
load(file="quadgrams.RData")
head(quad.dict)
quad.dict$element <- strsplit(as.character(quad.dict$Vocabulary), split = " ")
head(quad.dict)
save(quad.dict, file = "quadgram.RData")
str(quad.dict$element)
test1 <- quad.dict[1:5, 4]
test2 <- quad.dict
rm(test2)
test2 <- quad.dict[115:123, 4]
test <- rbind(test1, test2)
test <- c(test1, test2)
test
"thanks" !%in% test[[11]]
!"thanks" %in% test[[11]]
GetNext <- function(vocin) {
option <- c("", "", "", "")
l <- length(vocin)
if(l >= 3) {
phrase4 <- paste(vocin[l-2], vocin[l-1], vocin[l], sep=" ", collapse = " ")
phrase4 <- paste("^", phrase4, " ", sep="")
l4 <- length(grep(phrase4, quad.dict$Vocabulary))
idx4 <- head(grep(phrase4, quad.dict$Vocabulary), l4)
result4 <- quad.dict[idx, 4]
for(i in 1:min(4,l4)) list4[i] <- result4[[i]][4]
phrase3 <- paste(vocin[l-1], vocin[l], sep=" ", collapse = " ")
phrase3 <- paste("^", phrase3, " ", sep="")
l3 <- length(grep(phrase3, tri.dict$Vocabulary))
idx3 <- head(grep(phrase3, tri.dict$Vocabulary), l3)
result3 <- quad.dict[idx, 4]
for(i in 1:min(4,l3)) list3[i] <- result3[[i]][3]
phrase2 <- vocin[l]
phrase2 <- paste("^", phrases, " ", sep="")
l2 <- length(grep(phrase2, bi.dict$Vocabulary))
idx2 <- head(grep(phrase2, bi.dict$Vocabulary), l2)
result2 <- quad.dict[idx, 4]
for(i in 1:min(4,l2)) list2[i] <- result2[[i]][2]
ll <- c(list4, list3, list2)
i = 1; j = 1
while (i <= 4) {
if (ll[j] %in% option) j <- j+1
else {
option[i] <- ll[j]
i <- i+1; j <- j+1
}
}
}
}
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("is", "my", "favorite"))
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("is", "my", "favorite"))
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("is", "my", "favorite"))
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("is", "my", "favorite"))
load(file = "trigrams.RData")
load(file = "bigrams.RData")
load(file = "unigram.RData")
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("is", "my", "favorite"))
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("is", "my", "favorite"))
source('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
source('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("favorite", "place", "for"))
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("favorite", "place", "for"))
GetNext(c("favorite", "place", "for"))
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("favorite", "place", "for"))
debugSource('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
GetNext(c("favorite", "place", "for"))
source('~/Google Drive/Coursera-DataScience/Capstone Project/PredictiveKeyboard/GetNext2.R')
shiny::runApp()
